<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice Recording Test</title>
  <script src="https://cdn.socket.io/4.7.4/socket.io.min.js"></script>
  <style>
    body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }
    .container { max-width: 1200px; margin: 0 auto; }
    .section { margin: 20px 0; padding: 20px; border: 1px solid #ddd; border-radius: 8px; background: white; }
    .recording-controls { margin: 15px 0; }
    .recording-controls button { margin: 5px; padding: 12px 20px; border: none; border-radius: 5px; cursor: pointer; font-size: 14px; }
    .btn-record { background: #dc3545; color: white; }
    .btn-stop { background: #6c757d; color: white; }
    .btn-play { background: #28a745; color: white; }
    .btn-delete { background: #ffc107; color: black; }
    .btn-primary { background: #007bff; color: white; }
    .recording-status { margin: 15px 0; padding: 10px; border-radius: 5px; }
    .status-idle { background: #e9ecef; }
    .status-recording { background: #f8d7da; color: #721c24; animation: pulse 1s infinite; }
    .status-processing { background: #fff3cd; color: #856404; }
    .status-completed { background: #d4edda; color: #155724; }
    @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.7; } }
    .audio-visualizer { width: 100%; height: 60px; background: #000; margin: 10px 0; border-radius: 5px; }
    .recordings-list { margin: 15px 0; }
    .recording-item { padding: 15px; margin: 10px 0; border: 1px solid #dee2e6; border-radius: 8px; background: #fff; }
    .recording-item h5 { margin: 0 0 5px 0; }
    .recording-meta { font-size: 12px; color: #6c757d; margin: 5px 0; }
    audio { width: 100%; margin: 10px 0; }
    .connected { color: #28a745; font-weight: bold; }
    .disconnected { color: #dc3545; font-weight: bold; }
    .message-box { height: 200px; border: 1px solid #ccc; padding: 15px; overflow-y: auto; background: #f8f9fa; font-family: monospace; font-size: 12px; }
  </style>
</head>
<body>
<div class="container">
  <h1>üéôÔ∏è Voice Recording Test</h1>

  <div class="section">
    <h3>üîå Verbindung</h3>
    <div>Status: <span id="status" class="disconnected">Nicht verbunden</span></div>
    <div class="recording-controls">
      <button id="connectBtn" class="btn-primary">Verbinden</button>
      <button id="disconnectBtn" disabled>Trennen</button>
      <button id="refreshBtn" disabled>üîÑ Listen aktualisieren</button>
    </div>
  </div>

  <div class="section">
    <h3>üéôÔ∏è Audio-Aufnahme</h3>

    <div id="recordingStatus" class="recording-status status-idle">
      <strong>Status:</strong> <span id="recordingStatusText">Bereit f√ºr Aufnahme</span>
    </div>

    <div class="recording-controls">
      <button id="startRecordBtn" class="btn-record" disabled>üî¥ Aufnahme starten</button>
      <button id="stopRecordBtn" class="btn-stop" disabled>‚èπÔ∏è Aufnahme stoppen</button>
      <span id="formatInfo" class="webm-badge">WebM Format (Opus Codec)</span>
    </div>

    <canvas id="visualizer" class="audio-visualizer"></canvas>

    <div id="recordingInfo">
      <p><strong>Aufnahmezeit:</strong> <span id="recordingTime">00:00</span></p>
      <p><strong>Datengr√∂√üe:</strong> <span id="dataSize">0 KB</span></p>
    </div>
  </div>

  <div class="section">
    <h3>üìÅ Gespeicherte Aufnahmen</h3>
    <div id="recordingsList" class="recordings-list">
      <p>Keine Aufnahmen gefunden...</p>
    </div>
  </div>

  <div class="section">
    <h3>üéµ Audio Player</h3>
    <audio id="audioPlayer" controls>
      <p>Ihr Browser unterst√ºtzt das Audio-Element nicht.</p>
    </audio>
  </div>

  <div class="section">
    <h3>üìã Logs</h3>
    <div class="message-box" id="messages"></div>
  </div>
</div>

<script>
  let socket = null;
  let mediaRecorder = null;
  let audioContext = null;
  let analyser = null;
  let microphone = null;
  let isRecording = false;
  let currentSessionId = null;
  let recordingStartTime = null;
  let chunkSequence = 0;

  // DOM Elements
  const status = document.getElementById('status');
  const messages = document.getElementById('messages');
  const connectBtn = document.getElementById('connectBtn');
  const disconnectBtn = document.getElementById('disconnectBtn');
  const refreshBtn = document.getElementById('refreshBtn');
  const startRecordBtn = document.getElementById('startRecordBtn');
  const stopRecordBtn = document.getElementById('stopRecordBtn');
  const formatSelect = document.getElementById('formatSelect');
  const recordingStatus = document.getElementById('recordingStatus');
  const recordingStatusText = document.getElementById('recordingStatusText');
  const recordingTime = document.getElementById('recordingTime');
  const dataSize = document.getElementById('dataSize');
  const recordingsList = document.getElementById('recordingsList');
  const audioPlayer = document.getElementById('audioPlayer');
  const visualizer = document.getElementById('visualizer');

  let recordingTimeInterval = null;
  let totalDataSize = 0;

  function addMessage(message, type = 'info') {
    const timestamp = new Date().toISOString();
    const div = document.createElement('div');
    div.innerHTML = `<strong>[${timestamp}]</strong> ${message}`;
    div.style.color = type === 'error' ? '#dc3545' : type === 'success' ? '#28a745' : '#495057';
    div.style.marginBottom = '5px';
    messages.appendChild(div);
    messages.scrollTop = messages.scrollHeight;
    console.log(`[${type.toUpperCase()}] ${message}`);
  }

  function updateRecordingStatus(statusClass, statusText) {
    recordingStatus.className = `recording-status ${statusClass}`;
    recordingStatusText.textContent = statusText;
  }

  function formatFileSize(bytes) {
    if (bytes === 0) return '0 B';
    const k = 1024;
    const sizes = ['B', 'KB', 'MB', 'GB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
  }

  function formatTime(seconds) {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  }

  function setupAudioVisualization() {
    const canvas = visualizer;
    const canvasCtx = canvas.getContext('2d');
    canvas.width = canvas.offsetWidth;
    canvas.height = canvas.offsetHeight;

    function draw() {
      if (!analyser) return;

      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      analyser.getByteFrequencyData(dataArray);

      canvasCtx.fillStyle = 'rgb(0, 0, 0)';
      canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

      const barWidth = (canvas.width / bufferLength) * 2.5;
      let barHeight;
      let x = 0;

      for (let i = 0; i < bufferLength; i++) {
        barHeight = (dataArray[i] / 255) * canvas.height;

        canvasCtx.fillStyle = `rgb(${barHeight + 100}, 50, 50)`;
        canvasCtx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);

        x += barWidth + 1;
      }

      if (isRecording) {
        requestAnimationFrame(draw);
      }
    }

    if (isRecording) {
      draw();
    }
  }

  function displayRecordingsList(recordings) {
    if (!recordings || recordings.length === 0) {
      recordingsList.innerHTML = '<p>Keine Aufnahmen gefunden...</p>';
      return;
    }

    const listHtml = recordings.map(recording => {
      const badgeClass = recording.format === 'webm' ? 'webm-badge' : 'wav-badge';
      return `
                    <div class="recording-item">
                        <div style="display: flex; justify-content: space-between; align-items: center;">
                            <div>
                                <h5>üéµ ${recording.file}</h5>
                                <div class="recording-meta">
                                    <span class="${badgeClass}">${recording.format.toUpperCase()}</span> |
                                    Gr√∂√üe: ${formatFileSize(recording.size)} |
                                    Erstellt: ${new Date(recording.created).toLocaleString('de-DE')}
                                </div>
                            </div>
                            <div>
                                <button onclick="playRecording('${recording.file}')" class="btn-play">‚ñ∂Ô∏è Abspielen</button>
                                <button onclick="deleteRecording('${recording.file}')" class="btn-delete">üóëÔ∏è L√∂schen</button>
                            </div>
                        </div>
                    </div>
                `;
    }).join('');

    recordingsList.innerHTML = listHtml;
  }

  function playRecording(filename) {
    if (!socket || !socket.connected) {
      addMessage('Nicht verbunden!', 'error');
      return;
    }

    addMessage(`Streaming Aufnahme: ${filename}`, 'info');
    socket.emit('stream-recording', { filename });
  }

  function deleteRecording(filename) {
    if (!socket || !socket.connected) {
      addMessage('Nicht verbunden!', 'error');
      return;
    }

    if (confirm(`Aufnahme "${filename}" wirklich l√∂schen?`)) {
      addMessage(`L√∂sche Aufnahme: ${filename}`, 'info');
      socket.emit('delete-recording', { filename });
    }
  }

  async function startRecording() {
    try {
      // Get microphone access with better settings
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 44100,
          channelCount: 1
        }
      });

      // Setup audio context for visualization
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioContext.createAnalyser();
      microphone = audioContext.createMediaStreamSource(stream);
      microphone.connect(analyser);
      analyser.fftSize = 256;

      // Try different MIME types for better compatibility
      let mimeType = 'audio/webm;codecs=opus';
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = 'audio/webm';
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = 'audio/ogg;codecs=opus';
          if (!MediaRecorder.isTypeSupported(mimeType)) {
            mimeType = 'audio/wav';
          }
        }
      }

      addMessage(`Using MIME type: ${mimeType}`, 'info');

      // Setup MediaRecorder
      mediaRecorder = new MediaRecorder(stream, {
        mimeType: mimeType,
        audioBitsPerSecond: 128000
      });

      // Start server recording session
      socket.emit('start-recording');

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0 && currentSessionId) {
          // Convert blob to base64 and send to server
          const reader = new FileReader();
          reader.onload = () => {
            const base64Data = reader.result.split(',')[1];
            socket.emit('audio-chunk', {
              sessionId: currentSessionId,
              chunk: base64Data,
              sequence: chunkSequence++
            });

            totalDataSize += event.data.size;
            dataSize.textContent = formatFileSize(totalDataSize);
          };
          reader.readAsDataURL(event.data);
        }
      };

      mediaRecorder.start(250); // Record in smaller chunks (250ms) for better streaming
      isRecording = true;
      recordingStartTime = Date.now();
      totalDataSize = 0;
      chunkSequence = 0;

      // Update UI
      updateRecordingStatus('status-recording', 'Aufnahme l√§uft...');
      startRecordBtn.disabled = true;
      stopRecordBtn.disabled = false;

      // Start time counter
      recordingTimeInterval = setInterval(() => {
        const elapsed = (Date.now() - recordingStartTime) / 1000;
        recordingTime.textContent = formatTime(elapsed);
      }, 1000);

      // Start visualization
      setupAudioVisualization();

      addMessage('Aufnahme gestartet', 'success');

    } catch (error) {
      addMessage(`Fehler beim Starten der Aufnahme: ${error.message}`, 'error');
      updateRecordingStatus('status-idle', 'Fehler beim Starten der Aufnahme');
    }
  }

  function stopRecording() {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
      mediaRecorder.stream.getTracks().forEach(track => track.stop());
    }

    if (audioContext) {
      audioContext.close();
    }

    if (recordingTimeInterval) {
      clearInterval(recordingTimeInterval);
    }

    isRecording = false;

    // Update UI
    updateRecordingStatus('status-processing', 'Verarbeitung l√§uft...');
    stopRecordBtn.disabled = true;

    // Stop server recording
    if (currentSessionId) {
      socket.emit('stop-recording', { sessionId: currentSessionId });
    }

    addMessage('Aufnahme gestoppt, Verarbeitung l√§uft...', 'info');
  }

  // Socket.io Event Handlers
  connectBtn.addEventListener('click', () => {
    socket = io('http://localhost:3000', {
      transports: ['websocket', 'polling'],
      timeout: 10000,
      forceNew: true
    });

    socket.on('connect', () => {
      status.textContent = `Verbunden (ID: ${socket.id})`;
      status.className = 'connected';
      connectBtn.disabled = true;
      disconnectBtn.disabled = false;
      refreshBtn.disabled = false;
      startRecordBtn.disabled = false;
      addMessage('Verbindung hergestellt!', 'success');
    });

    socket.on('disconnect', () => {
      status.textContent = 'Nicht verbunden';
      status.className = 'disconnected';
      connectBtn.disabled = false;
      disconnectBtn.disabled = true;
      refreshBtn.disabled = true;
      startRecordBtn.disabled = true;
      stopRecordBtn.disabled = true;
      addMessage('Verbindung getrennt', 'error');
    });

    socket.on('recording-started', (data) => {
      currentSessionId = data.sessionId;
      addMessage(`Aufnahme-Session gestartet: ${data.sessionId} (${data.format})`, 'success');
    });

    socket.on('chunk-received', (data) => {
      // Chunk acknowledged by server
    });

    socket.on('recording-completed', (data) => {
      addMessage(`Aufnahme abgeschlossen: ${data.filename} (${formatFileSize(data.size)})`, 'success');
      updateRecordingStatus('status-completed', `Aufnahme gespeichert als ${data.filename}`);

      // Reset UI
      setTimeout(() => {
        updateRecordingStatus('status-idle', 'Bereit f√ºr Aufnahme');
        startRecordBtn.disabled = false;
        formatSelect.disabled = false;
        recordingTime.textContent = '00:00';
        dataSize.textContent = '0 KB';
      }, 3000);

      currentSessionId = null;
    });

    socket.on('recording-error', (error) => {
      addMessage(`Aufnahme-Fehler: ${error.error}`, 'error');
      updateRecordingStatus('status-idle', 'Fehler bei der Aufnahme');

      // Reset UI
      startRecordBtn.disabled = false;
      stopRecordBtn.disabled = true;
      formatSelect.disabled = false;
      currentSessionId = null;
    });

    socket.on('recordings-list', (recordings) => {
      addMessage(`${recordings.length} Aufnahmen empfangen`, 'info');
      displayRecordingsList(recordings);
    });

    socket.on('recording-deleted', (data) => {
      addMessage(`Aufnahme gel√∂scht: ${data.filename}`, 'success');
    });

    // Audio streaming events (reuse from existing player)
    socket.on('audio-stream-start', (metadata) => {
      addMessage(`Stream gestartet: ${metadata.fileName}`, 'info');
    });

    socket.on('audio-chunk', (chunk) => {
      // Handle streaming chunks (same as existing implementation)
      // ... implement streaming logic here ...
    });

    socket.on('audio-stream-end', () => {
      addMessage('Stream abgeschlossen', 'success');
    });
  });

  disconnectBtn.addEventListener('click', () => {
    if (socket) socket.disconnect();
  });

  refreshBtn.addEventListener('click', () => {
    if (socket) {
      socket.emit('get-recordings');
      addMessage('Aufnahmen-Liste wird aktualisiert...', 'info');
    }
  });

  startRecordBtn.addEventListener('click', startRecording);
  stopRecordBtn.addEventListener('click', stopRecording);
</script>
</body>
</html>
